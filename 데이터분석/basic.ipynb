{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 알기\n",
    "- 여러 가지 문자열 치환 / re.compile(azAZ) 확인\n",
    "- 데이터 정보 / 역순으로 정렬 / 특정 열의 항목 포함되는 것 찾기 (=, <, >) / 여러 기준으로 정렬 / 상위 n개, & and | or\n",
    "- 최대 / 최소 / 중복 제거\n",
    "- group by \n",
    "- isnull, fillna\n",
    "\n",
    "help(), dir() 활용하기 \n",
    "\n",
    "-평균값 (가장 큰값 10개는 10번째 값으로 대체, 특정 컬럼에서 00보다 큰 값의 평균)\n",
    "-표준편차 (결측치가 있을 때 표준편차, 결측치를 채운 후 표준편차 80% 데잉터 중앙값으로 채움)\n",
    "-이상치들의 합\n",
    "-이상치 처리 (분류)\n",
    "\n",
    "kmeans??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류 vs 회귀(예측)\n",
    "타이타닉, 손글씨 / 분류 : DecisionTreeClassifier, RandomForestClassifier, SVC - StandardScaler()\n",
    "    숫자의 차이가 모델에 영향을 주지 않는 트리 계열 모델\n",
    "아이리스, 유방암, 집값, 와인 품질 / 회귀 : DecisionTreeRegressor, RandomForestRegressor, LogisticRegression, KNeighborsClassifier  SVR - MinMaxScaler()\n",
    "    숫자의 차이가 모델에 영향을 미치는 선형 계열 모델 (주로 원핫인코딩)\n",
    "    특성별로 데이터 스케일이 다르면, 특정 요소가 예측에 영향을 주지 않음. (스케일러 사용이유)\n",
    "\n",
    "라벨 인코딩 vs 원핫인코딩\n",
    "라벨 - 문자형을 정수형으로 인코딩 / 가중치의 차이가 생긴다. 트리 기반 알고리즘에서 사용 / 범주형 (성별, 과목, 성적)\n",
    "원핫 - 숫자의 크고 작은 특성을 없애기 위함 / 모든 문자열 값이 숫자형이어야 함, 2차원데이터가 필요함 / 선형\n",
    "LabelEncoder() + OneHotEncoder() = get_dummies()\n",
    "\n",
    "0. 분류, 회귀 구분\n",
    "1. 데이터 파악 :info() 확인, nan값 처리, 중복 제거, 시각화, 아웃라이어\n",
    "2. 인코딩( get_dummies() ), test_train (교차검증시)\n",
    "3. scaler\n",
    "4. model\n",
    "5. predict\n",
    "\n",
    "seaborn 그리기\n",
    "plt.boxplot(df.age)\n",
    "sns.catplot(kind='box',data=df, x='grade',y='price')\n",
    "sns.violinplot(data=df, x='Species', y='SepalLengthCm') => catplot + kdeplot\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.2f')\n",
    "\n",
    "null 값처리\n",
    "df.isnull().sum()\n",
    "평균으로 : df.age = df.age.fillna(df.age.mean())\n",
    "특정값 평균으로  : df.Age = df.Age.fillna(df.groupby('Name')['Age'].mean())\n",
    "많은 값 : df.cabin.value_counts()\n",
    "replace : \n",
    "\n",
    "feature 묶기(더하기, age 별로) / 삭제\n",
    "중복 제거 : df.duplicated().sum()\n",
    "drop : train = df.drop( [‘name’,‘age’,‘parch’ ], axis=1)\n",
    "def category_age(x):\n",
    "    if x < 10:\n",
    "        return 0\n",
    "    elif x < 20:\n",
    "        return 1\n",
    "    elif x < 30:\n",
    "        return 2\n",
    "    elif x < 40:\n",
    "        return 3\n",
    "    elif x < 50:\n",
    "        return 4\n",
    "    elif x < 60:\n",
    "        return 5\n",
    "    elif x < 70:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7    \n",
    "    \n",
    "train['Age_cat'] = train['Age'].apply(category_age)\n",
    "\n",
    "문자를 숫자로 (원핫 인코딩*)\n",
    "map : df.cabin = df.cabin.map({ ‘a’ : 0 , ‘b’ : 1, ‘c’ : 2 })\n",
    "\n",
    "특정값 추출 \n",
    "data[(data.Age>30) & (data.Survived==1)].groupby('Sex').count()\n",
    "df.loc [ df[\"points\"] > 3, \"penalty\"] = 0 \n",
    "     points칼럼이 3보다 큰 행들을 뽑아내서 , penalty칼럼에 0을 대입\n",
    "\n",
    "싸이킷런\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data, target_data, test_size = 0.3, stratify=target_data)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train,y_train)\n",
    "tree.score(x_test, y_test)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=10)\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "print('training set accuracy:', forest.score(x_train, y_train))\n",
    "print('test set accuracy:', forest.score(x_test, y_test))\n",
    "\n",
    "prediction_by_forest = forest.predict(x_test)\n",
    "\n",
    "\n",
    "====================================================\n",
    "예측 : Feature Scaling은 특징 값의 범위를 균일하게 맞춰주는 작업입니다.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) #fit_trasform() : fit() + transform()\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=10)\n",
    "forest.fit(X_train,y_train)  \n",
    "y_pred = forest.predict(X_test)\n",
    "print('Accuracy is:',forest.score(X_test,y_test))\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)  #train꺼로 transform한걸로 fit 중요!!!!\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 변화값: ', labels)\n",
    "# 인코딩 변화값:  [0 1 4 5 3 3 2 2]\n",
    "# 회귀 알고리즘에는 적용하면 안됨, 트리 계열의 알고리즘은 숫자의 이런 특성을 반영하지 않으므로 레이블 인코딩도 별 문제가 없음\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전기레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "labels = labels.reshape(-1,1)\n",
    "\n",
    "# 원-핫 인코딩을 적용\n",
    "oh_encoder = OneHotEncoder(categories='auto')\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "# 원-핫 인코딩 데이터\n",
    "# [[1. 0. 0. 0. 0. 0.]\n",
    "#  [0. 1. 0. 0. 0. 0.]\n",
    "#  [0. 0. 0. 0. 1. 0.]\n",
    "#  [0. 0. 0. 0. 0. 1.]\n",
    "#  [0. 0. 0. 1. 0. 0.]\n",
    "#  [0. 0. 0. 1. 0. 0.]\n",
    "#  [0. 0. 1. 0. 0. 0.]\n",
    "#  [0. 0. 1. 0. 0. 0.]]\n",
    "\n",
    "\n",
    "# get_dummies() : 판다스에서 이용할 수 있는 원핫 인코딩 API\n",
    "# 사이킷런의 OneHotEncoder와는 달리 문자열 카테고리 값을 숫자형으로 변환할 필요 없이 바로 변환됨\n",
    "df = pd.DataFrame({'item' : ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "pd.get_dummies(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  2\n",
       "1  1\n",
       "2  2\n",
       "3  1\n",
       "4  2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#대체\n",
    "import pandas as pd\n",
    "data = pd.DataFrame([0, 1, 0, 1, 0])\n",
    "data = data.replace(0, 2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정렬\n",
    "df = df.sort_values('f5', ascending=False) #컬럼 기준 내림차순\n",
    "df = df.sort_values(['f5','f6'], ascending=False) #여러 컬럼 오름차순, 내림차순 ascendig=[False, True] 가능\n",
    "df = df.sort_index() #인덱스 기준 올림차순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#표준편차\n",
    "np.std(df.col1)\n",
    "\n",
    "#평균값\n",
    "df.col1.mean()\n",
    "\n",
    "#중간값\n",
    "df.col1.median()\n",
    "\n",
    "#절대값\n",
    "np.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 \n",
    "df.isnull().sum() #확인\n",
    "df.col1.fillna('특정값') #채우기\n",
    "df.dropna() #결측치 포함된거 다 지움\n",
    "df.dropna(axis=0)\n",
    "df.dropna(how='any') #결측치 있는 행 다 지워짐\n",
    "df.dropna(axis=1) #결측치 있는 열 다 지워짐\n",
    "\n",
    "df = df.dropna(subset=['col1']) #특정 열 결측치 제거 \n",
    "df = df.dropna(how='any',subset=['col1','col2']) #특정 열 둘 중 하나 결측치 있을 때 / 모두 결측치 있을 때 how ='all'\n",
    "\n",
    "\n",
    "#drop\n",
    "df.drop(['idx1','idx2']) #행 \n",
    "df.drop(['col1','col2'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby\n",
    "df_sum = df.groupby(['col1','col2']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분류를 위해서 나눔\n",
    "def category_age(x):\n",
    "    if x < 10:\n",
    "        return 0\n",
    "    elif x < 20:\n",
    "        return 1\n",
    "    elif x < 30:\n",
    "        return 2\n",
    "    elif x < 40:\n",
    "        return 3\n",
    "    elif x < 50:\n",
    "        return 4\n",
    "    elif x < 60:\n",
    "        return 5\n",
    "    elif x < 70:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7    \n",
    "    \n",
    "train['Age_cat'] = train['Age'].apply(category_age)\n",
    "test['Age_cat'] = test['Age'].apply(category_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#매핑 / 데이터 수치화\n",
    "train['Embarked'] = train['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "test['Embarked'] = test['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "#or\n",
    "train['Sex'].replace({'male':0, 'female':1}, inplace=True)\n",
    "\n",
    "\n",
    "#원핫인코딩\n",
    "train = pd.get_dummies(train, columns=['Initial'], prefix='Initial')\n",
    "test = pd.get_dummies(test, columns=['Initial'], prefix='Initial')\n",
    "\n",
    "#이후에 중복 feature 삭제\n",
    "train.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "test.drop(['PassengerId', 'Name',  'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', '_AXIS_LEN', '_AXIS_ORDERS', '_AXIS_REVERSED', '_AXIS_TO_AXIS_NUMBER', '_HANDLED_TYPES', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__array_ufunc__', '__array_wrap__', '__bool__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__divmod__', '__doc__', '__eq__', '__finalize__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__imod__', '__imul__', '__init__', '__init_subclass__', '__invert__', '__ior__', '__ipow__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_accessors', '_accum_func', '_add_numeric_operations', '_agg_by_level', '_agg_examples_doc', '_agg_summary_and_see_also_doc', '_aggregate', '_align_frame', '_align_series', '_arith_method', '_attrs', '_box_col_values', '_builtin_table', '_can_fast_transpose', '_check_inplace_and_allows_duplicate_labels', '_check_inplace_setting', '_check_is_chained_assignment_possible', '_check_label_or_level_ambiguity', '_check_setitem_copy', '_clear_item_cache', '_clip_with_one_bound', '_clip_with_scalar', '_cmp_method', '_combine_frame', '_consolidate', '_consolidate_inplace', '_construct_axes_dict', '_construct_axes_from_arguments', '_construct_result', '_constructor', '_constructor_expanddim', '_constructor_sliced', '_convert', '_count_level', '_cython_table', '_data', '_dir_additions', '_dir_deletions', '_dispatch_frame_op', '_drop_axis', '_drop_labels_or_levels', '_ensure_valid_index', '_find_valid_index', '_flags', '_from_arrays', '_get_agg_axis', '_get_axis', '_get_axis_name', '_get_axis_number', '_get_axis_resolvers', '_get_block_manager_axis', '_get_bool_data', '_get_cacher', '_get_cleaned_column_resolvers', '_get_column_array', '_get_cython_func', '_get_index_resolvers', '_get_item_cache', '_get_label_or_level_values', '_get_numeric_data', '_get_value', '_getitem_bool_array', '_getitem_multilevel', '_gotitem', '_hidden_attrs', '_indexed_same', '_info_axis', '_info_axis_name', '_info_axis_number', '_info_repr', '_init_mgr', '_inplace_method', '_internal_names', '_internal_names_set', '_is_builtin_func', '_is_cached', '_is_copy', '_is_homogeneous_type', '_is_label_or_level_reference', '_is_label_reference', '_is_level_reference', '_is_mixed_type', '_is_view', '_iset_item', '_item_cache', '_iter_column_arrays', '_ix', '_ixs', '_join_compat', '_logical_func', '_logical_method', '_maybe_cache_changed', '_maybe_update_cacher', '_metadata', '_mgr', '_min_count_stat_function', '_needs_reindex_multi', '_obj_with_exclusions', '_protect_consolidate', '_reduce', '_reindex_axes', '_reindex_columns', '_reindex_index', '_reindex_multi', '_reindex_with_indexers', '_replace_columnwise', '_repr_data_resource_', '_repr_fits_horizontal_', '_repr_fits_vertical_', '_repr_html_', '_repr_latex_', '_reset_cache', '_reset_cacher', '_sanitize_column', '_selected_obj', '_selection', '_selection_list', '_selection_name', '_series', '_set_as_cached', '_set_axis', '_set_axis_name', '_set_axis_nocheck', '_set_is_copy', '_set_item', '_set_value', '_setitem_array', '_setitem_frame', '_setitem_slice', '_slice', '_stat_axis', '_stat_axis_name', '_stat_axis_number', '_stat_function', '_stat_function_ddof', '_take_with_is_copy', '_to_dict_of_blocks', '_try_aggregate_string_function', '_typ', '_update_inplace', '_validate_dtype', '_values', '_where', 'abs', 'add', 'add_prefix', 'add_suffix', 'age', 'agg', 'aggregate', 'align', 'all', 'any', 'append', 'apply', 'applymap', 'asfreq', 'asof', 'assign', 'astype', 'at', 'at_time', 'attrs', 'axes', 'backfill', 'between_time', 'bfill', 'bool', 'boxplot', 'city', 'clip', 'columns', 'combine', 'combine_first', 'compare', 'convert_dtypes', 'copy', 'corr', 'corrwith', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'div', 'divide', 'dot', 'drop', 'drop_duplicates', 'droplevel', 'dropna', 'dtypes', 'duplicated', 'empty', 'eq', 'equals', 'eval', 'ewm', 'expanding', 'explode', 'f1', 'f2', 'f3', 'f4', 'f5', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'flags', 'floordiv', 'from_dict', 'from_records', 'ge', 'get', 'groupby', 'gt', 'head', 'hist', 'iat', 'id', 'idxmax', 'idxmin', 'iloc', 'index', 'infer_objects', 'info', 'insert', 'interpolate', 'isin', 'isna', 'isnull', 'items', 'iteritems', 'iterrows', 'itertuples', 'join', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'loc', 'lookup', 'lt', 'mad', 'mask', 'max', 'mean', 'median', 'melt', 'memory_usage', 'merge', 'min', 'mod', 'mode', 'mul', 'multiply', 'ndim', 'ne', 'nlargest', 'notna', 'notnull', 'nsmallest', 'nunique', 'pad', 'pct_change', 'pipe', 'pivot', 'pivot_table', 'plot', 'pop', 'pow', 'prod', 'product', 'quantile', 'query', 'radd', 'rank', 'rdiv', 'reindex', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'select_dtypes', 'sem', 'set_axis', 'set_flags', 'set_index', 'shape', 'shift', 'size', 'skew', 'slice_shift', 'sort_index', 'sort_values', 'squeeze', 'stack', 'std', 'style', 'sub', 'subtract', 'sum', 'swapaxes', 'swaplevel', 'tail', 'take', 'to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_feather', 'to_gbq', 'to_hdf', 'to_html', 'to_json', 'to_latex', 'to_markdown', 'to_numpy', 'to_parquet', 'to_period', 'to_pickle', 'to_records', 'to_sql', 'to_stata', 'to_string', 'to_timestamp', 'to_xarray', 'transform', 'transpose', 'truediv', 'truncate', 'tz_convert', 'tz_localize', 'unstack', 'update', 'value_counts', 'values', 'var', 'where', 'xs']\n",
      "Help on method drop in module pandas.core.frame:\n",
      "\n",
      "drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise') method of pandas.core.frame.DataFrame instance\n",
      "    Drop specified labels from rows or columns.\n",
      "    \n",
      "    Remove rows or columns by specifying label names and corresponding\n",
      "    axis, or by specifying directly index or column names. When using a\n",
      "    multi-index, labels on different levels can be removed by specifying\n",
      "    the level.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    labels : single label or list-like\n",
      "        Index or column labels to drop.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Whether to drop labels from the index (0 or 'index') or\n",
      "        columns (1 or 'columns').\n",
      "    index : single label or list-like\n",
      "        Alternative to specifying axis (``labels, axis=0``\n",
      "        is equivalent to ``index=labels``).\n",
      "    columns : single label or list-like\n",
      "        Alternative to specifying axis (``labels, axis=1``\n",
      "        is equivalent to ``columns=labels``).\n",
      "    level : int or level name, optional\n",
      "        For MultiIndex, level from which the labels will be removed.\n",
      "    inplace : bool, default False\n",
      "        If False, return a copy. Otherwise, do operation\n",
      "        inplace and return None.\n",
      "    errors : {'ignore', 'raise'}, default 'raise'\n",
      "        If 'ignore', suppress error and only existing labels are\n",
      "        dropped.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or None\n",
      "        DataFrame without the removed index or column labels or\n",
      "        None if ``inplace=True``.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    KeyError\n",
      "        If any of the labels is not found in the selected axis.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.loc : Label-location based indexer for selection by label.\n",
      "    DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      "        where (all or any) data are missing.\n",
      "    DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      "        removed, optionally only considering certain columns.\n",
      "    Series.drop : Return Series with specified index labels removed.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
      "    ...                   columns=['A', 'B', 'C', 'D'])\n",
      "    >>> df\n",
      "       A  B   C   D\n",
      "    0  0  1   2   3\n",
      "    1  4  5   6   7\n",
      "    2  8  9  10  11\n",
      "    \n",
      "    Drop columns\n",
      "    \n",
      "    >>> df.drop(['B', 'C'], axis=1)\n",
      "       A   D\n",
      "    0  0   3\n",
      "    1  4   7\n",
      "    2  8  11\n",
      "    \n",
      "    >>> df.drop(columns=['B', 'C'])\n",
      "       A   D\n",
      "    0  0   3\n",
      "    1  4   7\n",
      "    2  8  11\n",
      "    \n",
      "    Drop a row by index\n",
      "    \n",
      "    >>> df.drop([0, 1])\n",
      "       A  B   C   D\n",
      "    2  8  9  10  11\n",
      "    \n",
      "    Drop columns and/or rows of MultiIndex DataFrame\n",
      "    \n",
      "    >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      "    ...                              ['speed', 'weight', 'length']],\n",
      "    ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      "    ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      "    >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      "    ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      "    ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      "    ...                         [1, 0.8], [0.3, 0.2]])\n",
      "    >>> df\n",
      "                    big     small\n",
      "    lama    speed   45.0    30.0\n",
      "            weight  200.0   100.0\n",
      "            length  1.5     1.0\n",
      "    cow     speed   30.0    20.0\n",
      "            weight  250.0   150.0\n",
      "            length  1.5     0.8\n",
      "    falcon  speed   320.0   250.0\n",
      "            weight  1.0     0.8\n",
      "            length  0.3     0.2\n",
      "    \n",
      "    >>> df.drop(index='cow', columns='small')\n",
      "                    big\n",
      "    lama    speed   45.0\n",
      "            weight  200.0\n",
      "            length  1.5\n",
      "    falcon  speed   320.0\n",
      "            weight  1.0\n",
      "            length  0.3\n",
      "    \n",
      "    >>> df.drop(index='length', level=1)\n",
      "                    big     small\n",
      "    lama    speed   45.0    30.0\n",
      "            weight  200.0   100.0\n",
      "    cow     speed   30.0    20.0\n",
      "            weight  250.0   150.0\n",
      "    falcon  speed   320.0   250.0\n",
      "            weight  1.0     0.8\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#help, dir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('basic1.csv') \n",
    "# df = df.drop('f4')\n",
    "\n",
    "print(dir(df))\n",
    "print(help(df.drop))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19a2027c367e4a8fbf50703f7b521df71edff403eb9eba2200ef5f1febf03a5b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('exam_cv2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
